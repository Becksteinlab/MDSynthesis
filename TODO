=============
TODO List
=============

2014.08.12
----------
We will avoid multithreading at all costs. Instead, use separate processes.
Threads share the advisory lock of their process, which means that if an object
is using threads and these need to update the state file, the locks will mean
nothing.

2014.07.31
----------
Perhaps use PyTables directly for defining state files, and Pandas for handling
data. Example Sim state file:

HDF5 STRUCTURE
/
meta
coordinator
tags
categories
universes/
    main/
        topology
        trajectories
        selections

/
-------
meta : uuid, name, class, location
tags: tags
categories: category, value

universes/
----------
    main/ 
    -----
    topology: abspath, relhome, relSim
    trajectories: abspath, relhome, relSim
    selections: selection
    
We do not wish to store any information on user-generated data here, since this
will be stored in its own directory/HDF5 file. This allows one to delete these
directories without introducing inconsistencies.

Data aggregator will interface to individu

Be sure to use pytables flush method to ensure writes have finished before
removing exclusive lock.

For data access, will either need to wrap all access methods (including
indexing) with lock decorator, or require Sim.data.DATAINSTANCE.load prior to
use. Sim.data.DATAINSTANCE.unload will remove shared lock.
    + problem: will need separate mechanism for obtaining exclusive lock.
    + probably better to develop mechanism that applies shared lock before
      access, then removes it afterward. Likewise for modifiers. Can ponder
      this later; not necessary for usefulness when concurrent access not
      needed.
Need to play directly with pandas HDFStore interface. This will inform how we
go about applying the lock mechanisms. Possibly consider inheriting from
HDFStore and explicitly wrapping all functions appropriately.

For state files, can easily apply shared and exclusive locks using a decorator
on getters and setters, respectively. Access to these stored data will be
integrated into the Sim class. We have no need for pyTables query
functionality in this case (with perhaps exception of tags and categories).
    
Sim::
    add::
        universe()
        selection()
        data()
        tag()
        category()
        
    remove::
        universe()
        selection()
        data()
        tag()
        category()

    info?::

    attach::
        universe1

    universe -> Universe

    selections::
        selection1 -> atomgroup

    data::
        instance -> pandas HDFStore
        insance2
    
Overall scheme
==============
Sean Seyler and and I are collaborating to make this package work well as the
lower-level infrastructure for two different purposes, and it will fucking rock.

To make it easier to build, I propose we split the workload for now as follows:

    + Containers: I will focus on Container functionality. This is the most 
        well-developed at the moment, and there is a lot of existing code to
        wade through to improve them.

    + Operators: Sean is exceptional at optimization and algorithm design, and
        the Operators need plenty of design TLC. They are mostly just skeletons at
        present.  I suggest this be his area of expertise. Operators take in
        Containers as input, efficiently perform work on them, then give the
        Container the resulting data (in whatever form; python structures, plots,
        etc.) to store away.

    + Coordinator: This is basically the highest level Container of the whole scheme.
        It allows Containers to find each other when moved, and will allow the user
        to summon whole sets of Containers using selection queries (not implemented
        yet). I will focus on this, since it does not need to know anything about
        Operators but works intimately with Containers.

    + Core.Files: We will both need to brainstorm on building these file interfaces.
        The idea is that any change to a file class is immediately reflected in the
        file on disk, and vice-versa. The file class state should always
        reflect the file on disk's state, even if the file on disk is being
        altered by other instances of the file class at the same time. This
        will require some special magick.

    + Core.Aggregators: These classes serve as interfaces to file data, possibly
        from multiple files at once. I will focus my efforts on the Container-specific
        aggregators (Info and its derivatives), while Sean will need to consider how
        the Data operator behaves given the form of Operator-generated data files.
        This is a bit of a gray area, because in principle the Containers will "have
        a" Data aggregator that serves as the interface to loaded data, and Operators
        will interact with this in dumping their own results to the Container.

    + Core.Workers: These are the grab-bag classes. The ObjectCore is a mixin for
        all user-level objects (Containers and Operators). Finder will be a class
        that specializes in finding missing Databases and Containers in the filesystem.
        It will be called by these classes when a persistent object can't be found.
        Utilities contains functions used frequently by higher-level class methods;
        they should not ever be needed by a user; each object has one. Each
        Container will also "have a" Attributes object, which is a safe space
        for users to define their own attributes of a Container that guarantees
        functionality won't be broken.

Core
====

+ class `File` needs a rewrite.
    + turn it into an interface for an instance of an MDS file (metadata, database, datafile)
    + will allow atomic (modification of individaul elements with no stale overwrites) editing
    + synced with actual file every time object is accessed.

+ add class `Metadata` that serves as an interface to metadata files
    + we'd like to move away from manual edits of the metadata in-object
    + basically, atomize changes made to the metadata to ensure that it can be
      user-edited while still avoiding stale writes
    + along with this idea is full persistence: before an object ever writes out
      metadata, it refreshes its copy first

+ add class `DBFile` for database.
    + every time database calls for attribute, gets re-read.

+ add class `Datafile` for individual datafiles.

+ class `Data` to handle multiple datafile instances for Operators
    + we will abandon the 1-file-per-operator mindset, placing no restriction
      on the number of files one can store data in.
    + will serve as interface to all data instances
    + this new paradigm will mesh with another: that Operator base classes are
      built with few prescriptive methods but instead contain decorators that
      can be mixed and matched to get powerful functionality with little work.

Containers
==========
Add `notes` metadata item for user-notes.


Containers.Sim
~~~~~~~~~~~~~~

Containers.Group
~~~~~~~~~~~~~~~~~

Containers.SuperGroup
~~~~~~~~~~~~~~~~~~~~~

Operators
=========

Operators.Anaysis
~~~~~~~~~~~~~~~~~

+ add a progressbar scheme that shows progress of multiple systems
  in a meaningful way; current one is meant for serial use.

+ rethink the basic paradigm with decorators
    + could have decorators that corresponds to timeseries, parallelism, or
    mix-n-match; basically, one only needs to write an analysis routine with
      minimal criteria, then decorate it!
    + will have to think hard on this to avoid too much magic that it
      obfuscates function.

Operators.MetaAnaysis
~~~~~~~~~~~~~~~~~~~~~

Operators.MacroAnaysis
~~~~~~~~~~~~~~~~~~~~~


Ideastorm (anything from pie-in-sky to random musing)
=====================================================

Classes for handling md systems that are still being run?
+ integration with GromacsWrapper?
+ globus-toolkit methods and/or classes?
-> these are probably outside the scope of MDSynthesis, but I am considering
   building an "applications" package that includes specific and useful Containers
   and Operators

Markov analysis class?
+ see Michael Grabe's work on mitochondrial channels

+ Create VMD operator that can take multiple objects and load all of them
  at once.

Globus Toolkit!
+ build an Operator that can perform globus tasks on container objects

Perhaps use IPython.Config as a prototype for a dictionary accessible as
attributes.

